{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "gradient": {
     "editing": false
    }
   },
   "source": [
    "## Attention Mechanisms in Computer Vision: CBAM\n",
    "\n",
    "For a more detailed breakdown of the Convolution Block Attention Module, check out the [full tutorial on the blog](https://blog.paperspace.com/attention-mechanisms-in-computer-vision-cbam/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "colab_type": "code",
    "gradient": {},
    "id": "QIW-dgNsj9ar",
    "outputId": "86e004a1-e6b2-4296-cb51-4349336b0221",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Model Parameter and FLOP counter\n",
    "!pip install --upgrade git+https://github.com/sovrasov/flops-counter.pytorch.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "# Download data\n",
    "!wget https://s3.amazonaws.com/ps.public.resources/ml-showcase/attention-mechanisms-in-computer-vision/data.zip\n",
    "!unzip data.zip -d ./\n",
    "!rm data.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 326
    },
    "colab_type": "code",
    "gradient": {},
    "id": "DWJZdmaBrqnY",
    "outputId": "847c4664-30ea-419e-cb6c-6f3842930d10"
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from ptflops import get_model_complexity_info\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import torch.nn.parallel\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "from torch.nn.parameter import Parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "gradient": {}
   },
   "outputs": [],
   "source": [
    "best_prec1 = 0\n",
    "evaluate = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "gradient": {},
    "id": "_ccW_-r0ZAFP"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "    global best_prec1, evaluate\n",
    "\n",
    "    __all__ = ['ResNet', 'resnet20', 'resnet32', 'resnet44', 'resnet56', 'resnet110', 'resnet1202']\n",
    "\n",
    "\n",
    "    def _weights_init(m):\n",
    "        classname = m.__class__.__name__\n",
    "        #print(classname)\n",
    "        if isinstance(m, nn.Linear) or isinstance(m, nn.Conv2d):\n",
    "            init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "    class LambdaLayer(nn.Module):\n",
    "        def __init__(self, lambd):\n",
    "            super(LambdaLayer, self).__init__()\n",
    "            self.lambd = lambd\n",
    "\n",
    "        def forward(self, x):\n",
    "            return self.lambd(x)\n",
    "\n",
    "\n",
    "    class BasicConv(nn.Module):\n",
    "        def __init__(self, in_planes, out_planes, kernel_size, stride=1, padding=0, dilation=1, groups=1, relu=True, bn=True, bias=False):\n",
    "            super(BasicConv, self).__init__()\n",
    "            self.out_channels = out_planes\n",
    "            self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel_size, stride=stride, padding=padding, dilation=dilation, groups=groups, bias=bias)\n",
    "            self.bn = nn.BatchNorm2d(out_planes,eps=1e-5, momentum=0.01, affine=True) if bn else None\n",
    "            self.relu = nn.ReLU() if relu else None\n",
    "\n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            if self.bn is not None:\n",
    "                x = self.bn(x)\n",
    "            if self.relu is not None:\n",
    "                x = self.relu(x)\n",
    "            return x\n",
    "\n",
    "    class Flatten(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return x.view(x.size(0), -1)\n",
    "\n",
    "    class ChannelGate(nn.Module):\n",
    "        def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max']):\n",
    "            super(ChannelGate, self).__init__()\n",
    "            self.gate_channels = gate_channels\n",
    "            self.mlp = nn.Sequential(\n",
    "                Flatten(),\n",
    "                nn.Linear(gate_channels, gate_channels // reduction_ratio),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(gate_channels // reduction_ratio, gate_channels)\n",
    "                )\n",
    "            self.pool_types = pool_types\n",
    "        def forward(self, x):\n",
    "            channel_att_sum = None\n",
    "            for pool_type in self.pool_types:\n",
    "                if pool_type=='avg':\n",
    "                    avg_pool = F.avg_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                    channel_att_raw = self.mlp( avg_pool )\n",
    "                elif pool_type=='max':\n",
    "                    max_pool = F.max_pool2d( x, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                    channel_att_raw = self.mlp( max_pool )\n",
    "                elif pool_type=='lp':\n",
    "                    lp_pool = F.lp_pool2d( x, 2, (x.size(2), x.size(3)), stride=(x.size(2), x.size(3)))\n",
    "                    channel_att_raw = self.mlp( lp_pool )\n",
    "                elif pool_type=='lse':\n",
    "                    # LSE pool only\n",
    "                    lse_pool = logsumexp_2d(x)\n",
    "                    channel_att_raw = self.mlp( lse_pool )\n",
    "\n",
    "                if channel_att_sum is None:\n",
    "                    channel_att_sum = channel_att_raw\n",
    "                else:\n",
    "                    channel_att_sum = channel_att_sum + channel_att_raw\n",
    "\n",
    "            scale = torch.sigmoid( channel_att_sum ).unsqueeze(2).unsqueeze(3).expand_as(x)\n",
    "            return x * scale\n",
    "\n",
    "    def logsumexp_2d(tensor):\n",
    "        tensor_flatten = tensor.view(tensor.size(0), tensor.size(1), -1)\n",
    "        s, _ = torch.max(tensor_flatten, dim=2, keepdim=True)\n",
    "        outputs = s + (tensor_flatten - s).exp().sum(dim=2, keepdim=True).log()\n",
    "        return outputs\n",
    "\n",
    "    class ChannelPool(nn.Module):\n",
    "        def forward(self, x):\n",
    "            return torch.cat( (torch.max(x,1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim=1 )\n",
    "\n",
    "    class SpatialGate(nn.Module):\n",
    "        def __init__(self):\n",
    "            super(SpatialGate, self).__init__()\n",
    "            kernel_size = 7\n",
    "            self.compress = ChannelPool()\n",
    "            self.spatial = BasicConv(2, 1, kernel_size, stride=1, padding=(kernel_size-1) // 2, relu=False)\n",
    "        def forward(self, x):\n",
    "            x_compress = self.compress(x)\n",
    "            x_out = self.spatial(x_compress)\n",
    "            scale = torch.sigmoid(x_out) # broadcasting\n",
    "            return x * scale\n",
    "\n",
    "    class CBAM(nn.Module):\n",
    "        def __init__(self, gate_channels, reduction_ratio=16, pool_types=['avg', 'max'], no_spatial=False):\n",
    "            super(CBAM, self).__init__()\n",
    "            self.ChannelGate = ChannelGate(gate_channels, reduction_ratio, pool_types)\n",
    "            self.no_spatial=no_spatial\n",
    "            if not no_spatial:\n",
    "                self.SpatialGate = SpatialGate()\n",
    "        def forward(self, x):\n",
    "            x_out = self.ChannelGate(x)\n",
    "            if not self.no_spatial:\n",
    "                x_out = self.SpatialGate(x_out)\n",
    "            return x_out\n",
    "\n",
    "\n",
    "    class BasicBlock(nn.Module):\n",
    "        expansion = 1\n",
    "\n",
    "        def __init__(self, in_planes, planes, stride=1, option='A', use_cbam = True):\n",
    "            super(BasicBlock, self).__init__()\n",
    "            self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(planes)\n",
    "            self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn2 = nn.BatchNorm2d(planes)\n",
    "            self.use_cbam = use_cbam\n",
    "            if self.use_cbam == True:\n",
    "                self.cbam = CBAM(planes)\n",
    "\n",
    "            self.shortcut = nn.Sequential()\n",
    "            if stride != 1 or in_planes != planes:\n",
    "                if option == 'A':\n",
    "                    \"\"\"\n",
    "                    For CIFAR10 ResNet paper uses option A.\n",
    "                    \"\"\"\n",
    "                    self.shortcut = LambdaLayer(lambda x:\n",
    "                                                F.pad(x[:, :, ::2, ::2], (0, 0, 0, 0, planes//4, planes//4), \"constant\", 0))\n",
    "                elif option == 'B':\n",
    "                    self.shortcut = nn.Sequential(\n",
    "                        nn.Conv2d(in_planes, self.expansion * planes, kernel_size=1, stride=stride, bias=False),\n",
    "                        nn.BatchNorm2d(self.expansion * planes)\n",
    "                    )\n",
    "            \n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.bn2(self.conv2(out))\n",
    "            out += self.shortcut(x)\n",
    "            out = F.relu(out)\n",
    "            if self.use_cbam == True:\n",
    "                out = self.cbam(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    class ResNet(nn.Module):\n",
    "        def __init__(self, block, num_blocks, num_classes=10):\n",
    "            super(ResNet, self).__init__()\n",
    "            self.in_planes = 16\n",
    "\n",
    "            self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "            self.bn1 = nn.BatchNorm2d(16)\n",
    "            self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "            self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "            self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "            self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "            self.apply(_weights_init)\n",
    "\n",
    "        def _make_layer(self, block, planes, num_blocks, stride):\n",
    "            strides = [stride] + [1]*(num_blocks-1)\n",
    "            layers = []\n",
    "            for stride in strides:\n",
    "                layers.append(block(self.in_planes, planes, stride))\n",
    "                self.in_planes = planes * block.expansion\n",
    "\n",
    "            return nn.Sequential(*layers)\n",
    "\n",
    "        def forward(self, x):\n",
    "            out = F.relu(self.bn1(self.conv1(x)))\n",
    "            out = self.layer1(out)\n",
    "            out = self.layer2(out)\n",
    "            out = self.layer3(out)\n",
    "            out = F.avg_pool2d(out, out.size()[3])\n",
    "            out = out.view(out.size(0), -1)\n",
    "            out = self.linear(out)\n",
    "            return out\n",
    "\n",
    "\n",
    "    def resnet20():\n",
    "        return ResNet(BasicBlock, [3, 3, 3])\n",
    "\n",
    "\n",
    "    def resnet32():\n",
    "        return ResNet(BasicBlock, [5, 5, 5])\n",
    "\n",
    "\n",
    "    def resnet44():\n",
    "        return ResNet(BasicBlock, [7, 7, 7])\n",
    "\n",
    "\n",
    "    def resnet56():\n",
    "        return ResNet(BasicBlock, [9, 9, 9])\n",
    "\n",
    "\n",
    "    def resnet110():\n",
    "        return ResNet(BasicBlock, [18, 18, 18])\n",
    "\n",
    "\n",
    "    def resnet1202():\n",
    "        return ResNet(BasicBlock, [200, 200, 200])\n",
    "\n",
    "    model = resnet20()\n",
    "\n",
    "    with torch.cuda.device(0):\n",
    "      flops, params = get_model_complexity_info(model, (3, 224, 224), as_strings=True, print_per_layer_stat=True)\n",
    "      print('{:<30}  {:<8}'.format('Computational complexity: ', flops))\n",
    "      print('{:<30}  {:<8}'.format('Number of parameters: ', params))\n",
    "\n",
    "    model.cuda()\n",
    "\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "    normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                     std=[0.229, 0.224, 0.225])\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=True, transform=transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(32, 4),\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ]), download=True),\n",
    "        batch_size=128, shuffle=True,\n",
    "        num_workers=4, pin_memory=True)\n",
    "\n",
    "    val_loader = torch.utils.data.DataLoader(\n",
    "        datasets.CIFAR10(root='./data', train=False, transform=transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            normalize,\n",
    "        ])),\n",
    "        batch_size=128, shuffle=False,\n",
    "        num_workers=4, pin_memory=True)\n",
    "\n",
    "    # define loss function (criterion) and pptimizer\n",
    "    criterion = nn.CrossEntropyLoss().cuda()\n",
    "\n",
    "    optimizer = torch.optim.SGD(model.parameters(), 0.1,\n",
    "                                momentum=0.9,\n",
    "                                weight_decay=5e-4)\n",
    "\n",
    "    lr_scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                        milestones=[100, 150], last_epoch=0 - 1)\n",
    "\n",
    "\n",
    "    for epoch in range(0, 200):\n",
    "\n",
    "        # train for one epoch\n",
    "        print('current lr {:.5e}'.format(optimizer.param_groups[0]['lr']))\n",
    "        train(train_loader, model, criterion, optimizer, epoch)\n",
    "        lr_scheduler.step()\n",
    "\n",
    "        # evaluate on validation set\n",
    "        prec1 = validate(val_loader, model, criterion)\n",
    "\n",
    "        # remember best prec@1 and save checkpoint\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "\n",
    "        is_best = prec1 > best_prec1\n",
    "        best_prec1 = max(prec1, best_prec1)\n",
    "        if epoch > 0 and epoch % 20 == 0:\n",
    "            save_checkpoint({\n",
    "                'epoch': epoch + 1,\n",
    "                'state_dict': model.state_dict(),\n",
    "                'best_prec1': best_prec1,\n",
    "            }, is_best, filename=os.path.join('./', 'vanilla_checkpoint.th'))\n",
    "\n",
    "        save_checkpoint({\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_prec1': best_prec1,\n",
    "        }, is_best, filename=os.path.join('./', 'vanilla_model.th'))\n",
    "\n",
    "\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch):\n",
    "    \"\"\"\n",
    "        Run one train epoch\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to train mode\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(train_loader):\n",
    "\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        target = target.cuda()\n",
    "        input_var = input.cuda()\n",
    "        target_var = target\n",
    "\n",
    "        # compute output\n",
    "        output = model(input_var)\n",
    "        loss = criterion(output, target_var)\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        output = output.float()\n",
    "        loss = loss.float()\n",
    "        # measure accuracy and record loss\n",
    "        prec1 = accuracy(output.data, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "        if i % 20 == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                      epoch, i, len(train_loader), batch_time=batch_time,\n",
    "                      data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "\n",
    "def validate(val_loader, model, criterion):\n",
    "    \"\"\"\n",
    "    Run evaluation\n",
    "    \"\"\"\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "            target = target.cuda()\n",
    "            input_var = input.cuda()\n",
    "            target_var = target.cuda()\n",
    "\n",
    "\n",
    "            # compute output\n",
    "            output = model(input_var)\n",
    "            loss = criterion(output, target_var)\n",
    "\n",
    "            output = output.float()\n",
    "            loss = loss.float()\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec1 = accuracy(output.data, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec1.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % 20 == 0:\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                      'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                      'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                      'Prec@1 {top1.val:.3f} ({top1.avg:.3f})'.format(\n",
    "                          i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                          top1=top1))\n",
    "\n",
    "    print(' * Prec@1 {top1.avg:.3f}'\n",
    "          .format(top1=top1))\n",
    "\n",
    "    return top1.avg\n",
    "\n",
    "def save_checkpoint(state, is_best, filename='checkpoint.pth.tar'):\n",
    "    \"\"\"\n",
    "    Save the training model\n",
    "    \"\"\"\n",
    "    torch.save(state, filename)\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "b325f811fac64863a96afc641697e66b",
      "20c79cab95f64266806943f5d7af63ff",
      "6816eb4990fa4d3e88a891cb62392a08",
      "794da6e36fc44937a46966c7b1d9d586",
      "86787348b60143f9bd0325eb119665de",
      "357441019723462fa39d743f79b1ea3f",
      "60038776476f40a283a7f4b14a39feab",
      "d23a629db428427a9b21522d92325ea4"
     ]
    },
    "colab_type": "code",
    "gradient": {},
    "id": "SgWEssqXirta",
    "outputId": "d5818acc-2af3-44cb-c948-6bb00617e86c"
   },
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "ResNet_CBAM.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "20c79cab95f64266806943f5d7af63ff": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "357441019723462fa39d743f79b1ea3f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "60038776476f40a283a7f4b14a39feab": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6816eb4990fa4d3e88a891cb62392a08": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_357441019723462fa39d743f79b1ea3f",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_86787348b60143f9bd0325eb119665de",
      "value": 1
     }
    },
    "794da6e36fc44937a46966c7b1d9d586": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d23a629db428427a9b21522d92325ea4",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_60038776476f40a283a7f4b14a39feab",
      "value": " 170500096/? [00:06&lt;00:00, 24882056.35it/s]"
     }
    },
    "86787348b60143f9bd0325eb119665de": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "b325f811fac64863a96afc641697e66b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_6816eb4990fa4d3e88a891cb62392a08",
       "IPY_MODEL_794da6e36fc44937a46966c7b1d9d586"
      ],
      "layout": "IPY_MODEL_20c79cab95f64266806943f5d7af63ff"
     }
    },
    "d23a629db428427a9b21522d92325ea4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
